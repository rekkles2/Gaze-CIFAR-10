# Gaze-Guided Learning: Avoiding Shortcut Bias in Visual Classification

## Overview  
This repository implements a gaze-guided learning approach to improve visual classification by mitigating shortcut bias. The model is based on Vision Transformer (ViT) and trained on the Gaze-CIFAR-10 dataset.  

## Pretrained Model  
The pretrained ViT model can be downloaded from the following link:  
[ViT Pretrained Model](https://drive.google.com/file/d/1FPUIYmZ4ooMbWByXUzBRNGLcrIYvNsxz/view?usp=drive_link)  

## Dataset  
The Gaze-CIFAR-10 dataset can be downloaded from:  
[Gaze-CIFAR-10ðŸš€ðŸš€ðŸš€](https://drive.google.com/drive/folders/17zR9bIDWvb0FzSEgR2vXJIKo3w6wKDVB?usp=drive_link)  

## Training  
To train the model, run:  
```bash
python train.py
```  

## Testing  
To evaluate the model, run:  
```bash
python predict1.py
```  

## Citation  
If you use this code or dataset in your research, please cite accordingly.  
